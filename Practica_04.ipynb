{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3dbcf51",
   "metadata": {},
   "source": [
    "# Practica 4\n",
    "## Captcha Destroyer hecho por: Python Haters\n",
    "#### - Hugo Vivanco Fernandez\n",
    "#### - Jaime Isar Muñoz\n",
    "#### - Daniel Lafuente Bazo\n",
    "#### - Óscar Fabián Pineda Germán"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba692a31",
   "metadata": {},
   "source": [
    "## Parte 0: Tratamiento de imagenes\n",
    "Trabajamos con .png y tenemos que ser capaces de procesarlos, para esto usaremos cv2 (OpenCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a463814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "symbols = string.ascii_lowercase + string.digits    # Todos los digitos que contienen los CAPTCHAs\n",
    "directorio_input = 'samples/'                       # Directorio de CAPTCHAs sin filtrar\n",
    "directorio_output_filtrado = 'samples_transform/'            # Directorio de CAPTCHAs como imagen binaria\n",
    "CAPTCHA_LENGHT = 5                                  # Numero de caracteres por CAPTCHA                                  \n",
    "formato_imagen = (50, 200, 1)                       # Contador de imagenes procesadas en total\n",
    "\n",
    "\n",
    "def convertir_imagen(ruta_input, ruta_output, dimension=(50, 200)):\n",
    "\n",
    "    # Abrir imagen\n",
    "    imagen = Image.open(ruta_input)\n",
    "    \n",
    "    # Cambiar tamaño\n",
    "    imagen = imagen.resize(dimension)\n",
    "    \n",
    "    # Convertir a blanco y negro\n",
    "    imagen_bn = imagen.convert('L')  # 'L' es modo de 8 bits en escala de grises\n",
    "    \n",
    "    # Guardar la nueva imagen\n",
    "    imagen_bn.save(ruta_output)\n",
    "\n",
    "def imagen_a_matriz(ruta_imagen, umbral=128):\n",
    "\n",
    "    imagen = Image.open(ruta_imagen)    # Abrir imagen\n",
    "    \n",
    "    imagen_bn = imagen.point(lambda p: 255 if p > umbral else 0)    # Convertir a imagen binaria\n",
    "    \n",
    "    imagen_array = np.array(imagen_bn)  # Tranformar a numpy array\n",
    "\n",
    "    matriz = np.where(imagen_array == 0, 1, 0)  # Invertir pixeles\n",
    "\n",
    "    matriz = np.expand_dims(matriz, axis=-1)  # Convertir a: (200, 50, 1)\n",
    "\n",
    "    return matriz\n",
    "\n",
    "def codificar_solucion(nombre_imagen : str):\n",
    "\n",
    "    symbols_size = len(symbols)\n",
    "    one_hot = np.zeros((CAPTCHA_LENGHT, symbols_size))\n",
    "    index = 0\n",
    "    for char in nombre_imagen:\n",
    "        index_in_symbols = symbols.find(char)\n",
    "        one_hot[index, index_in_symbols] = 1    # hot_one codification\n",
    "        index += 1\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "def obtener_datos_de_imagenes():\n",
    "\n",
    "    datos = []          # (n*200*50*1): Num datos * 200 * 50 * 1\n",
    "    soluciones = []     # Solucion para cada imagen\n",
    "    contador = 0        # Contador de imágenes procesadas\n",
    "\n",
    "    for archivo in os.listdir(directorio_input):\n",
    "        archivo_nuevo = directorio_output_filtrado + archivo  # Ruta de la imagen\n",
    "        nombre_imagen = archivo[:-4]  # Quitar el .png para obtener la solución (texto del captcha)\n",
    "\n",
    "        if os.path.isfile(archivo_nuevo):\n",
    "            datos.append(imagen_a_matriz(archivo_nuevo))    # Añade matriz de imagen\n",
    "            soluciones.append(nombre_imagen)                # Añade la solucion de esta imagen \n",
    "            contador += 1\n",
    "\n",
    "    return datos, soluciones, contador\n",
    "\n",
    "def one_hot_encode(soluciones):\n",
    "\n",
    "    n = len(soluciones)\n",
    "    y = np.zeros( (CAPTCHA_LENGHT, n, len(symbols)) )  # (5, n, 36) : 5 letras, n imágenes, 36 posibles caracteres\n",
    "\n",
    "    for i, texto in enumerate(soluciones):\n",
    "        for j, letra in enumerate(texto):\n",
    "            index = symbols.find(letra)\n",
    "            if index != -1:\n",
    "                y[j, i, index] = 1\n",
    "\n",
    "    return y\n",
    "\n",
    "def createmodel():\n",
    "\n",
    "    # Bloque de entrada\n",
    "    lista_neuronas_input = layers.Input(shape=formato_imagen)\n",
    "\n",
    "    # Primer bloque\n",
    "    convolutional_layer1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(lista_neuronas_input)\n",
    "    max_pooling_1 = layers.MaxPooling2D(pool_size=(2, 2))(convolutional_layer1)\n",
    "\n",
    "    # Segundo bloque\n",
    "    convolutional_layer2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(max_pooling_1)\n",
    "    max_pooling_2 = layers.MaxPooling2D(pool_size=(2, 2))(convolutional_layer2)\n",
    "\n",
    "    # Tercer bloque\n",
    "    convolutional_layer3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(max_pooling_2)\n",
    "    batch_normalitation = layers.BatchNormalization()(convolutional_layer3) # Mejora la estabilidad(N) -> Media=0 y desviacion estandar=1\n",
    "    max_pooling_3 = layers.MaxPooling2D(pool_size=(2, 2))(batch_normalitation)\n",
    "    flatten_layer = layers.Flatten()(max_pooling_3)\n",
    "\n",
    "    lista_neuronas_output = []\n",
    "    for _ in range(5):\n",
    "        input_layer = layers.Dense(64, activation='relu')(flatten_layer)\n",
    "        outupt_layer = layers.Dense(len(symbols), activation='sigmoid')(input_layer)\n",
    "        lista_neuronas_output.append( layers.Dense(36, activation='softmax')(outupt_layer) )\n",
    "\n",
    "\n",
    "    modelo = models.Model(inputs=lista_neuronas_input, outputs=lista_neuronas_output)\n",
    "    modelo.compile(loss=['categorical_crossentropy'], optimizer='adam', metrics=['accuracy'] * CAPTCHA_LENGHT)  # Nuestra red tiene 5 salidas, una por letra del captcha\n",
    "    return modelo\n",
    "\n",
    "def predict(filepath):\n",
    "    \n",
    "    img = imagen_a_matriz(filepath)\n",
    "\n",
    "    res = np.array( modelo.predict(img) )\n",
    "\n",
    "    #added this bcoz x_train 970*50*200*1\n",
    "    #returns array of size 1*5*36 \n",
    "    result = np.reshape(res, (5, 36)) #reshape the array\n",
    "    k_ind = []\n",
    "    for i in result:\n",
    "        k_ind.append(np.argmax(i)) #adds the index of the char found in captcha\n",
    "\n",
    "    capt = '' #string to store predicted captcha\n",
    "    for k in k_ind:\n",
    "        capt += symbols[k] #finds the char corresponding to the index\n",
    "\n",
    "    return capt \n",
    "\n",
    "def test(modelo, j=20):\n",
    "\n",
    "    # Listar todas las imágenes en el directorio\n",
    "    imagenes = [f for f in os.listdir('samples_transform') if f.endswith('.png')]\n",
    "\n",
    "    # Elegir j imágenes aleatorias\n",
    "    seleccionadas = random.sample(imagenes, j)\n",
    "\n",
    "    for nombre_imagen in seleccionadas:\n",
    "\n",
    "        ruta = os.path.join('samples_transform', nombre_imagen)\n",
    "        img = imagen_a_matriz(ruta)\n",
    "        img = np.expand_dims(img, axis=0)  # Añade dimensión batch (1, 50, 200, 1)\n",
    "\n",
    "        # Pasar la imagen por la red\n",
    "        predicciones = modelo.predict(img)\n",
    "\n",
    "        # Decodificar predicciones\n",
    "        resultado = ''\n",
    "        for salida in predicciones:\n",
    "            idx = np.argmax(salida)\n",
    "            resultado += symbols[idx]\n",
    "\n",
    "        print(f'Imagen: {nombre_imagen[:-4]} ➔ Predicción: {resultado}')\n",
    "\n",
    "\n",
    "modelo = ''\n",
    "if os.path.exists('modelo.h5'):\n",
    "    modelo = load_model('modelo.h5')\n",
    "else:\n",
    "    X_data, Y_data, numImagenes = obtener_datos_de_imagenes()\n",
    "    Y_data = one_hot_encode(Y_data)\n",
    "\n",
    "    # Crear modelo\n",
    "    modelo = createmodel()\n",
    "    modelo.summary()    # Mostrar caracteristicas\n",
    "\n",
    "    # División de datos\n",
    "    split_index = int(numImagenes * 0.8)    # Obtener numero de datos usados para entrenar\n",
    "    X_train, X_test = X_data[:split_index], X_data[split_index:]    # Datos usados para entrenar y para testear\n",
    "    Y_train, Y_test = Y_data[:split_index], Y_data[split_index:]    # Soluciones de los datos usados para entrenar y para testear\n",
    "\n",
    "    # Entrenar modelo\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    hist = modelo.fit(\n",
    "        X_train,\n",
    "        [Y_train[0], Y_train[1], Y_train[2], Y_train[3], Y_train[4]],\n",
    "        batch_size=32,\n",
    "        epochs=60,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    modelo.save('modelo.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830fb15e",
   "metadata": {},
   "source": [
    "## Parte 1: Reconocer un dígito o letra deformado\n",
    "\n",
    "Para empezar el proyecto decidimos ir paso a paso. Primero identificaremos numeros y letras de forma individual. (logic CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b777b3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Imagen: e8e5e ➔ Predicción: ensym\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Imagen: gfbx6 ➔ Predicción: gnvyx\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Imagen: gwnm6 ➔ Predicción: gnxyx\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Imagen: 5f3gf ➔ Predicción: 5nvxx\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Imagen: nbcgb ➔ Predicción: envyw\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Imagen: y53c2 ➔ Predicción: cnsxm\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Imagen: pg4bf ➔ Predicción: d9s1x\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Imagen: 5pm6b ➔ Predicción: 59vdx\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Imagen: 5n3w4 ➔ Predicción: 59vyy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Imagen: men4f ➔ Predicción: g9xyx\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Imagen: fp382 ➔ Predicción: f9vyx\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Imagen: d3c8y ➔ Predicción: dns1m\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Imagen: 4n3mn ➔ Predicción: 4nxyx\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Imagen: 7fde7 ➔ Predicción: 7nvyx\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Imagen: 4dgf7 ➔ Predicción: 4ns1x\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Imagen: dn2ym ➔ Predicción: dnx1x\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Imagen: 2yggg ➔ Predicción: 2nsyx\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Imagen: bbymy ➔ Predicción: bn8xx\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Imagen: nxn4f ➔ Predicción: ens1x\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Imagen: 8wy7d ➔ Predicción: 8nvym\n"
     ]
    }
   ],
   "source": [
    "test(modelo=modelo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
