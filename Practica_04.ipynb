{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3dbcf51",
   "metadata": {},
   "source": [
    "# Practica 4\n",
    "## Captcha Destroyer :por: Python Eaters\n",
    "#### - Hugo Vivanco Fernandez\n",
    "#### - Jaime Isar Muñoz\n",
    "#### - Daniel Lafuente Bazo\n",
    "#### - Óscar Fabián Pineda Germán"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0155ab25",
   "metadata": {},
   "source": [
    "## Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6191073",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstring\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m \n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import numpy as np \n",
    "import cv2 #OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba692a31",
   "metadata": {},
   "source": [
    "## Parte 0: Tratamiento de imagenes\n",
    "Trabajamos con .png y tenemos que ser capaces de procesarlos, para esto usaremos cv2 (OpenCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab06989",
   "metadata": {},
   "source": [
    "Primero necesitamos saber cuales son los caracteres que nos podemos encontrar en los 'catcha' y, ya que estamos, la cantidad de caracteres que son."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = string.ascii_lowercase + \"0123456789\" # All symbols captcha can contain\n",
    "numChar = len(symbols) # numero de chars posibles\n",
    "numChar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f17f7",
   "metadata": {},
   "source": [
    "Luego de cuantas imagenes es unuestro Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99bfb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tamanio del dataset \n",
    "directory_examples = \"C:\\Users\\NITROPC\\OneDrive\\Escritorio\\Daniel\\Trabajo\\Universidad\\4º Año\\2ºCuatri\\SI\\Practica 4\\SI_CaptchaDestroller\\samples\"\n",
    "n = len(os.listdir(directory_examples))\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e506fe",
   "metadata": {},
   "source": [
    "Despues queremos preprocesar las imagenes con las que estemos trabajando, para asegurarnos que todas tengan el mismo formato y dimensiones.\n",
    "Notese que el nombre de la imagen es la solucion del catchap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ee0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_img():\n",
    "    img_array = np.zeros((n,50,200,1)) # n = 1070 (tamanio del dataset ) * 50 (altura de la imagen) * 200 (anchura de la imagen) (con todas las entradas a 0)\n",
    "    letersImg_array = np.zeros((5,n,numChar)) # 5 (letras de catchap) * n = 1070 (tamanio del dataset ) * 36 (posibles caracteres)  (con todas las entradas a 0)\n",
    "\n",
    "    for i, pic in enumerate(os.listdir(directory_examples)):\n",
    "    # i : indice en el que se encuentra la imagen en el directorio (0-(n-1))->(n)\n",
    "    # pic : contiene el nombre de la imagen en posicion i, que es equivalente a la solucion del catchap + .png\n",
    "        \n",
    "        img = cv2.imread(os.path.join(directory_examples, pic), cv2.IMREAD_GRAYSCALE) #guardamos la imagen en forma de matriz en una escala de blanco y negro\n",
    "        pic_target = pic[:-4]# guardamos el objetimo (solucion del catchap), que es quivalente a el nombre - .png (.png = 4bits => -4)\n",
    "\n",
    "        if len(pic_target) < 6: #solo captcha de 5 letras o menos\n",
    "            img = img / 255.0 #escalar la imagen entre 0 y 1\n",
    "            img = np.reshape(img, (50, 200, 1)) #redimensionas el array a 200 de ancho, 50 de alto , en channel 1 \n",
    "\n",
    "            target=np.zeros((5,numChar)) #5 (letras de catchap) * 36 (posibles caracteres)  (con todas las entradas a 0) = (ej: 0:0,0,....(36),0; 0:0,0,...)\n",
    "\n",
    "            for j, k in enumerate(pic_target):\n",
    "            # j : indice en el que se encuentra la palabra (0-4)->(5)\n",
    "            # k : letra correspondiente a la pos j\n",
    "                indexSymbol = symbols.find(k) # indexSymbol guarda la pos de la letra k, respecto al array de  symbols\n",
    "                target[j, indexSymbol] = 1 # en la posicion j : remplazo en la pos index el 0 por un 1 (ej: en la pos j esta la letra m)\n",
    "\n",
    "            img_array[i] = img # guardo las imagen en pos i \n",
    "            letersImg_array[:,i] = target # guardo el target (solucion) en pos i\n",
    "\n",
    "    return img_array, letersImg_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830fb15e",
   "metadata": {},
   "source": [
    "## Parte 1: Reconocer un dígito o letra deformado\n",
    "\n",
    "Para empezar el proyecto decidimos ir paso a paso. Primero identificaremos numeros y letras de forma individual. (logic CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b777b3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f3ace36",
   "metadata": {},
   "source": [
    "## Parte 2: Reconocer una cadena de dígitos y letras bien separadas\n",
    "Ahora que sabemos identificar letras y números por separado podemos agruparlos bien separados en una cadena para leerlos y escribirlos en orden de aparición. (logic RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6792f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "827de68d",
   "metadata": {},
   "source": [
    "## Parte 3: Reconocer dígitos y letras que se juntan/mezclan\n",
    "Por último queda ser capaces de distinguir los números y letras que están solapados en la cadena para poder escribirlos (CRNN = CNN + RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d7f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
